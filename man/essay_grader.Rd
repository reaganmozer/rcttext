% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/essay_grader.R
\name{essay_grader}
\alias{essay_grader}
\alias{ChatGPT}
\title{Grading Essays or Generating Responses with ChatGPT}
\usage{
essay_grader(text, prompt, model)

ChatGPT(prompt, model = "gpt-3.5-turbo", my_API = NULL, temp = 0)
}
\arguments{
\item{text}{A vector of text strings to be graded or used as input for generating responses.}

\item{prompt}{A string containing the prompt to be sent to the ChatGPT model.}

\item{model}{A string specifying the model to be used, with "gpt-3.5-turbo" as the default.}

\item{my_API}{A string containing the ChatGPT API key. If NULL, the function will attempt to use an API key stored in the global environment.}

\item{temp}{A numeric value between 0 and 1 that controls the randomness of the model's output, with 0 as the default for deterministic results.}
}
\value{
A data frame with generated responses or graded results for each input text.

A string containing the generated response from the ChatGPT model.
}
\description{
This function grades essays or generates responses based on given prompts
and texts using a specified model.
To run this function, you need to have your own ChatGPT API key.

This function interacts with the ChatGPT API to generate responses based on a given prompt.
The function allows for a global fallback mechanism for the API key if not provided explicitly.
}
\examples{
# Assign your own ChatGPT API key
my_API <- "your-api-key-here"

# Define example texts and prompt
texts <- c("This is the first essay.", "Here is another essay.")
prompt <- "Evaluate the quality of this essay."

# Specify the model to use
model <- "gpt-3.5-turbo"

# Run the essay_grader function
graded_essays <- essay_grader(texts, prompt, model)

# View the results
print(graded_essays)
# Example usage with explicit API key
response <- ChatGPT("What is the capital of France?", model = "gpt-3.5-turbo", my_API = "your-api-key-here")

# Example usage with global API key
my_API <- "your-api-key-here"
response <- ChatGPT("What is the capital of France?", model = "gpt-3.5-turbo")

# Example usage with different temperature
response <- ChatGPT("Generate a creative story", model = "gpt-3.5-turbo", temp = 0.7)

}
