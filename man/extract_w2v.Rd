% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/extract_w2v.R
\name{extract_w2v}
\alias{extract_w2v}
\title{Compute document-level feature vectors from a pre-trained embedding
model.}
\usage{
extract_w2v(x, meta = NULL, model = NULL)
}
\arguments{
\item{x}{A \link{corpus} object or character vector of text
documents.}

\item{meta}{Dataframe corresponding to the corpus x.  If passed,
and non-NULL, all generated features will be added to this
dataframe.  If NULL, a dataframe of just the features will be
returned.}

\item{model}{User-specified model object pointing to a custom
pre-trained embedding model, represented as a matrix or data frame where the
first column is the word/token and the following columns are numeric vectors.  If
NULL, use default "mini_glove" embeddings on 1000 common words
(not recommended).}
}
\value{
A list of data frames containing the Word2Vec projections
  of the corpus
}
\description{
This function generates a vector embedding for each word in a
string using a set of pre-trained word vectors such as GloVe
\insertCite{pennington2014glove}{rcttext} and returns the mean vector
projection across all words in a document.
}
\examples{

# The txt_data should be a dataframe

library(textdata)
data("example_meta")

txt_data = meta
glove.50d = embedding_glove6b(dimensions = 50)

all.feats = extract_w2v( clean_text( text$text ),
                         meta = txt_data,
                         model = glove.50d )

}
\references{
references
\insertRef{mikolov2013efficient}{rcttext}
\insertRef{pennington2014glove}{rcttext}
}
