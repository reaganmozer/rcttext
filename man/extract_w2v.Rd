% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/extract_w2v.R
\name{extract_w2v}
\alias{extract_w2v}
\title{Compute document-level feature vectors from a pre-trained embedding
model.}
\usage{
extract_w2v(x, meta = NULL, model = NULL)
}
\arguments{
\item{x}{A \link{corpus} object or character vector of text
documents.}

\item{meta}{Dataframe corresponding to the corpus x.  If passed,
and non-NULL, all features will be added to this dataframe.}

\item{model}{User-specified model object pointing to a custom
pre-trained embedding model, represented as a matrix or data frame where the
first column is the word/token and the following columns are numeric vectors.  If
NULL, use default "mini_glove" embeddings on 1000 common words
(not recommended).}
}
\value{
A list of data frames containing the Word2Vec projections
  of the corpus
}
\description{
This function generates a vector embedding for each word in a
string using a set of pre-trained word vectors such as GloVe
\insertCite{pennington2014glove}{rcttext} and returns the mean vector
projection across all words in a document.
}
\references{
{ \insertRef{mikolov2013efficient}{rcttext}
\insertRef{pennington2014glove}{rcttext} }
}
